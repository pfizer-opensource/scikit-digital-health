{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from PfyMU.gait.train_classifier.core import load_datasets\n",
    "from PfyMU.features import *\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = {\n",
    "    'jumping-rope': 0.15,\n",
    "    'stairs-descending': 0.1,\n",
    "    'stairs-ascending': 0.1,\n",
    "    'jumping': 0.15,\n",
    "    'lying': 0.15,\n",
    "    'elevator-ascending': 0.15,\n",
    "    'elevator-descending': 0.15,\n",
    "    'running': 0.075,\n",
    "    'sweeping': 0.15,\n",
    "    'standing': 225,\n",
    "    'running-treadmill': 0.1,\n",
    "    'cycling-50W': 0.12,\n",
    "    'cycling-100W': 0.12,\n",
    "    'walking-left': 0.2,\n",
    "    'walking-right': 0.2,\n",
    "    'walking-impaired': 0.2,\n",
    "    'walking': 0.25,\n",
    "    'sitting': 400,\n",
    "    'default': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gait_sets_path = Path('/Users/adamol/Documents/Datasets/gait/processed')\n",
    "gait_sets_path = Path('/home/lukasadamowicz/Documents/Datasets/processed')\n",
    "\n",
    "datasets = [\n",
    "    gait_sets_path / 'bluesky2',\n",
    "    gait_sets_path / 'daliac',\n",
    "    gait_sets_path / 'ltmm',\n",
    "    gait_sets_path / 'usc-had'\n",
    "]\n",
    "\n",
    "X, Y, subjects, activities = load_datasets(\n",
    "    datasets, \n",
    "    goal_fs=50.0, \n",
    "    acc_mag=True, \n",
    "    window_length=3.0, \n",
    "    window_step=steps\n",
    ")\n",
    "\n",
    "# make stair-climbing in the positive class\n",
    "mask = (activities == 'stairs-ascending') | (activities == 'stairs-descending')\n",
    "Y_inc_str = Y.copy()\n",
    "Y_inc_str[mask] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_df = pd.DataFrame(data={'Subject': subjects, 'Activity': activities})\n",
    "sa_df['col1'] = 1.0\n",
    "\n",
    "# get the subjects for which LOSO actually makes sense: those with multiple activities (ie more than just walking)\n",
    "gbc = sa_df.groupby(['Subject', 'Activity'], as_index=False).count()\n",
    "loso_subjects = [i for i in gbc.Subject.unique() if gbc.loc[gbc.Subject == i].shape[0] > 3]\n",
    "\n",
    "random.seed(5)  # fix the generation so that its the same every time\n",
    "random.shuffle(loso_subjects)\n",
    "\n",
    "training_masks = []\n",
    "validation_masks = []\n",
    "testing_masks = []\n",
    "\n",
    "for i in range(0, len(loso_subjects), 4):\n",
    "    tr_m = np.ones(sa_df.shape[0], dtype='bool')\n",
    "    v_m = np.zeros(sa_df.shape[0], dtype='bool')\n",
    "    te_m = np.zeros(sa_df.shape[0], dtype='bool')\n",
    "    \n",
    "    for j in range(4):\n",
    "        tr_m &= (sa_df.Subject != loso_subjects[i+j]).values\n",
    "    for j in range(2):\n",
    "        v_m |= (sa_df.Subject == loso_subjects[i+j]).values\n",
    "    for j in range(2):\n",
    "        te_m |= (sa_df.Subject == loso_subjects[i+j+2]).values\n",
    "    \n",
    "    training_masks.append(tr_m)\n",
    "    validation_masks.append(v_m)\n",
    "    testing_masks.append(te_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "FB = Bank(window_length=None, window_step=None)\n",
    "\n",
    "# add features\n",
    "FB + Mean()\n",
    "FB + MeanCrossRate()\n",
    "FB + StdDev()\n",
    "FB + Skewness()\n",
    "FB + Kurtosis()\n",
    "FB + Range()\n",
    "FB + IQR()\n",
    "FB + RMS()\n",
    "FB + LinearSlope()\n",
    "FB + SignalEntropy()\n",
    "FB + SPARC()\n",
    "FB + ComplexityInvariantDistance(normalize=True)\n",
    "FB + JerkMetric(normalize=True)\n",
    "FB + DimensionlessJerk(log=True, signal_type='acceleration')\n",
    "\n",
    "FB + Autocorrelation(lag=1, normalize=True)\n",
    "FB + Autocorrelation(lag=15, normalize=True)\n",
    "FB + Autocorrelation(lag=14, normalize=True)\n",
    "FB + Autocorrelation(lag=12, normalize=True)\n",
    "\n",
    "FB + SampleEntropy(m=4, r=1.0)\n",
    "FB + SampleEntropy(m=2, r=0.75)\n",
    "FB + SampleEntropy(m=3, r=0.75)\n",
    "FB + SampleEntropy(m=2, r=0.5)\n",
    "FB + SampleEntropy(m=2, r=0.25)\n",
    "\n",
    "FB + PermutationEntropy(order=3, delay=1, normalize=True)\n",
    "FB + PermutationEntropy(order=5, delay=1, normalize=True)\n",
    "FB + PermutationEntropy(order=8, delay=1, normalize=True)\n",
    "FB + PermutationEntropy(order=10, delay=1, normalize=True)\n",
    "FB + PermutationEntropy(order=8, delay=2, normalize=True)\n",
    "FB + PermutationEntropy(order=8, delay=8, normalize=True)\n",
    "\n",
    "FB + RangeCountPercentage(range_min=0, range_max=1.0)\n",
    "FB + RangeCountPercentage(range_min=0.5, range_max=1.4)\n",
    "FB + RangeCountPercentage(range_min=0.3, range_max=1.4)\n",
    "FB + RangeCountPercentage(range_min=1, range_max=1.4)\n",
    "FB + RangeCountPercentage(range_min=0, range_max=1.5)\n",
    "\n",
    "FB + RatioBeyondRSigma(r=1.0)\n",
    "FB + RatioBeyondRSigma(r=2.5)\n",
    "FB + RatioBeyondRSigma(r=0.5)\n",
    "\n",
    "FB + DominantFrequency(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + DominantFrequency(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + DominantFrequency(low_cutoff=1.0, high_cutoff=3.0)\n",
    "FB + DominantFrequency(low_cutoff=1.5, high_cutoff=6.0)\n",
    "FB + DominantFrequency(low_cutoff=0.5, high_cutoff=3.0)\n",
    "\n",
    "FB + DominantFrequencyValue(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + DominantFrequencyValue(low_cutoff=1.0, high_cutoff=3.5)\n",
    "FB + DominantFrequencyValue(low_cutoff=1.0, high_cutoff=3.0)\n",
    "FB + DominantFrequencyValue(low_cutoff=1.5, high_cutoff=6.0)\n",
    "FB + DominantFrequencyValue(low_cutoff=0.5, high_cutoff=3.0)\n",
    "\n",
    "FB + PowerSpectralSum(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + PowerSpectralSum(low_cutoff=1.0, high_cutoff=3.0)\n",
    "FB + PowerSpectralSum(low_cutoff=1.5, high_cutoff=3.5)\n",
    "FB + PowerSpectralSum(low_cutoff=0.25, high_cutoff=4.0)\n",
    "FB + PowerSpectralSum(low_cutoff=0.25, high_cutoff=3.0)\n",
    "\n",
    "FB + SpectralFlatness(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=6.0)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=8.0)\n",
    "FB + SpectralFlatness(low_cutoff=0.0, high_cutoff=3.5)\n",
    "FB + SpectralFlatness(low_cutoff=0.5, high_cutoff=3.5)\n",
    "\n",
    "FB + SpectralEntropy(low_cutoff=0.25, high_cutoff=5.0)\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=5.0)\n",
    "FB + SpectralEntropy(low_cutoff=0.0, high_cutoff=3.5)\n",
    "FB + SpectralEntropy(low_cutoff=0.25, high_cutoff=3.0)\n",
    "FB + SpectralEntropy(low_cutoff=1.5, high_cutoff=4.0)\n",
    "\n",
    "FB + DetailPower(wavelet='coif4', freq_band=[1.0, 3.0])\n",
    "\n",
    "FB + DetailPowerRatio(wavelet='coif4', freq_band=[1.0, 3.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lukasadamowicz/miniconda3/envs/pfymu/lib/python3.8/site-packages/pywt/_multilevel.py:43: UserWarning: Level value of 6 is too high: all coefficients will experience boundary effects.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_feat, feature_names = FB.compute(X, fs=50.0, windowed=True, columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pd.DataFrame(\n",
    "    index=range(X_feat.shape[0]), \n",
    "#     columns=['Subject', 'Activity', 'Label'] + feature_names,\n",
    "    columns=['Label'] + feature_names,\n",
    "    dtype='float'\n",
    ")\n",
    "# feats['Subject'] = feats.Subject.astype('str')\n",
    "# feats['Activity'] = feats.Activity.astype('str')\n",
    "\n",
    "feats.iloc[:, 1:] = X_feat\n",
    "feats['Label'] = Y\n",
    "feats['Label'] = feats.Label.astype('int')\n",
    "# feats['Subject'] = subjects\n",
    "# feats['Activity'] = activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_istr = pd.DataFrame(\n",
    "    index=range(X_feat.shape[0]), \n",
    "    columns=['Label'] + feature_names,\n",
    "    dtype='float'\n",
    ")\n",
    "\n",
    "feats_istr.iloc[:, 1:] = X_feat\n",
    "feats_istr['Label'] = Y_inc_str\n",
    "feats_istr['Label'] = feats_istr.Label.astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Elimintation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_cls = lgb.LGBMClassifier(n_estimators=75, random_state=82)\n",
    "tree_cls = DecisionTreeClassifier(random_state=398)\n",
    "\n",
    "lgb_rfecv = RFECV(\n",
    "    lgb_cls, \n",
    "    step=1, \n",
    "    min_features_to_select=1, \n",
    "    cv=tuple(zip(training_masks, validation_masks)),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "tree_rfecv = RFECV(\n",
    "    tree_cls,\n",
    "    step=1,\n",
    "    min_features_to_select=1,\n",
    "    cv=tuple(zip(training_masks, validation_masks)),\n",
    "    scoring=make_scorer(f1_score),\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n"
     ]
    }
   ],
   "source": [
    "lgb_slc = lgb_rfecv.fit(feats.iloc[:, 1:], feats.Label)\n",
    "lgb_slc_istr = clone(lgb_rfecv).fit(feats_istr.iloc[:, 1:], feats_istr.Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 64 features.\n",
      "Fitting estimator with 63 features.\n",
      "Fitting estimator with 62 features.\n",
      "Fitting estimator with 61 features.\n",
      "Fitting estimator with 60 features.\n",
      "Fitting estimator with 59 features.\n",
      "Fitting estimator with 58 features.\n",
      "Fitting estimator with 57 features.\n",
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n"
     ]
    }
   ],
   "source": [
    "tree_slc = tree_rfecv.fit(feats.iloc[:, 1:], feats.Label);\n",
    "tree_slc_istr = clone(tree_rfecv).fit(feats_istr.iloc[:, 1:], feats_istr.Label);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LGB number of features : 40\n",
      "LGB number of features, stairs=positive : 20\n",
      "Tree number of features: 46\n",
      "Tree number of features, stairs=positive: 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f5c3550d0444262823d0f67374ca8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"LGB number of features : %d\" % lgb_slc.n_features_)\n",
    "print(\"LGB number of features, stairs=positive : %d\" % lgb_slc_istr.n_features_)\n",
    "print(f'Tree number of features: {tree_slc.n_features_}')\n",
    "print(f'Tree number of features, stairs=positive: {tree_slc_istr.n_features_}')\n",
    "\n",
    "lgb_score = lgb_slc.grid_scores_\n",
    "lgb_s_score = lgb_slc_istr.grid_scores_\n",
    "tr_score = tree_slc.grid_scores_\n",
    "tr_s_score = tree_slc_istr.grid_scores_\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.set_xlabel(\"Number of features selected\")\n",
    "ax.set_ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "ax.plot(range(1, len(lgb_score) + 1), lgb_score* 100, '.-', label='LGB', color='C0')\n",
    "ax.plot(range(1, len(lgb_s_score) + 1), lgb_s_score * 100, '.--', label='LGB, stairs', color='C0')\n",
    "ax.plot(range(1, len(tr_score)+1), tr_score*100, '.-', label='Tree', color='C1')\n",
    "ax.plot(range(1, len(tr_s_score)+1), tr_s_score*100, '.-', label='Tree, stairs', color='C1')\n",
    "\n",
    "axx = ax.twinx()\n",
    "axx.grid(False)\n",
    "axx.plot(range(1, len(lgb_score)), np.diff(lgb_score) / lgb_score[:-1] * 100, '.', label=f'LGB: N={lgb_slc.n_features_}', color='C0')\n",
    "axx.plot(range(1, len(lgb_s_score)), np.diff(lgb_s_score) / lgb_s_score[:-1] * 100, '+', label=f'LGB, stairs: N={lgb_slc_istr.n_features_}', color='C0')\n",
    "axx.plot(range(1, len(tr_score)), np.diff(tr_score) / tr_score[:-1] * 100, '.', label=f'Tree: N={tree_slc.n_features_}')\n",
    "axx.plot(range(1, len(tr_s_score)), np.diff(tr_s_score) / tr_s_score[:-1] * 100, '+', label=f'Tree, stairs: N={tree_slc_istr.n_features_}')\n",
    "axx.axhline(0.2, linestyle='--', color='k')\n",
    "axx.text(24, 0.7, '0.2% Change')\n",
    "axx.set_ylabel('% Score % Change')\n",
    "\n",
    "axx.set_ylim(-0.5, 10)\n",
    "\n",
    "axx.legend(loc=5)\n",
    "\n",
    "f.tight_layout()\n",
    "f.savefig('RFECV_results.png', bbox='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean', 'meancrossrate', 'stddev', 'skewness', 'kurtosis', 'range',\n",
       "       'iqr', 'linearslope', 'signalentropy',\n",
       "       'complexityinvariantdistance_True', 'jerkmetric',\n",
       "       'dimensionlessjerk_True_acceleration', 'autocorrelation_1_True',\n",
       "       'autocorrelation_15_True', 'autocorrelation_14_True',\n",
       "       'autocorrelation_12_True', 'sampleentropy_4_1.00',\n",
       "       'sampleentropy_2_0.50', 'sampleentropy_2_0.25',\n",
       "       'permutationentropy_3_1_True', 'permutationentropy_8_1_True',\n",
       "       'permutationentropy_8_2_True', 'permutationentropy_8_8_True',\n",
       "       'rangecountpercentage_0_1.00', 'rangecountpercentage_1_1.40',\n",
       "       'ratiobeyondrsigma_1.00', 'ratiobeyondrsigma_0.50',\n",
       "       'dominantfrequency_0.25_5.00', 'dominantfrequency_1.00_3.00',\n",
       "       'dominantfrequency_1.50_6.00', 'dominantfrequencyvalue_0.25_5.00',\n",
       "       'dominantfrequencyvalue_1.00_3.50',\n",
       "       'dominantfrequencyvalue_1.00_3.00', 'powerspectralsum_1.00_3.00',\n",
       "       'spectralflatness_0.00_8.00', 'spectralflatness_0.00_3.50',\n",
       "       'spectralentropy_0.00_5.00', 'spectralentropy_0.00_3.50',\n",
       "       'detailpower_coif4_[1.0, 3.0]',\n",
       "       'detailpowerratio_coif4_[1.0, 3.0]'], dtype='<U35')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(feature_names)[lgb_slc.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean', 'meancrossrate', 'stddev', 'skewness', 'range', 'iqr',\n",
       "       'signalentropy', 'jerkmetric', 'autocorrelation_1_True',\n",
       "       'autocorrelation_15_True', 'autocorrelation_12_True',\n",
       "       'sampleentropy_2_0.50', 'permutationentropy_3_1_True',\n",
       "       'permutationentropy_8_1_True', 'rangecountpercentage_0_1.00',\n",
       "       'rangecountpercentage_0.50_1.40', 'ratiobeyondrsigma_0.50',\n",
       "       'dominantfrequencyvalue_1.00_3.50', 'spectralentropy_0.00_3.50',\n",
       "       'detailpowerratio_coif4_[1.0, 3.0]'], dtype='<U35')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(feature_names)[lgb_slc_istr.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PfyMU",
   "language": "python",
   "name": "pfymu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
